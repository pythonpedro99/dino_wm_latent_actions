{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PushT discretization verification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook inspects the discretized PushT datasets, confirms that every new artifact was generated, and compares\n",
    "them against the original continuous-action data. It is intended to be rerunnable whenever the discretization pipeline\n",
    "is updated or a new dataset copy is produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports & configuration ===\n",
    "import os, gc, math, pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "SPLITS = (\"train\", \"val\")\n",
    "ACTIONS_FNAME = \"rel_actions.pth\"\n",
    "ABS_ACTIONS_FNAME = \"abs_actions.pth\"\n",
    "VELOCITIES_FNAME = \"velocities.pth\"\n",
    "STATES_FNAME = \"states.pth\"\n",
    "STATE_CONSTANT_FNAME = \"states_constant.pth\"\n",
    "LENGTHS_FNAME = \"seq_lengths.pkl\"\n",
    "TOKENS_FNAME = \"tokens.pth\"\n",
    "VARIANTS = (\"kmeans_k9\", \"kmeans_k15\", \"fixed_compass_r24\")\n",
    "SUBSET_SPECS = {\"1k\": 1_000, \"10k\": 10_000}\n",
    "\n",
    "def _resolve_dataset_dir(path_str: str, default_leaf: str = \"pusht_noise\") -> Path:\n",
    "    base = Path(path_str).expanduser()\n",
    "    if (base / \"train\").exists() and (base / \"val\").exists():\n",
    "        return base\n",
    "    candidate = base / default_leaf\n",
    "    if (candidate / \"train\").exists() and (candidate / \"val\").exists():\n",
    "        return candidate\n",
    "    raise FileNotFoundError(f\"Could not resolve dataset directory from {path_str!r}. Provide SRC_DATASET_DIR or DATASET_DIR.\")\n",
    "\n",
    "src_root_env = os.getenv(\"SRC_DATASET_DIR\", os.getenv(\"DATASET_DIR\", \"data\"))\n",
    "SRC_DATASET_DIR = _resolve_dataset_dir(src_root_env)\n",
    "dst_root_env = os.getenv(\"DST_DATASET_DIR\", str(SRC_DATASET_DIR.parent / \"pusht_noise_discretized\"))\n",
    "DST_DATASET_DIR = Path(dst_root_env).expanduser()\n",
    "\n",
    "subset_roots = {name: DST_DATASET_DIR.parent / f\"{DST_DATASET_DIR.name}_{name}\" for name in SUBSET_SPECS}\n",
    "\n",
    "print(f\"Source dataset       : {SRC_DATASET_DIR}\")\n",
    "print(f\"Discretized dataset  : {DST_DATASET_DIR}\")\n",
    "print(f\"Subset roots         : {subset_roots}\")\n",
    "print(f\"Variants             : {VARIANTS}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Helper utilities ===\n",
    "def load_lengths(split_dir: Path) -> np.ndarray:\n",
    "    with open(split_dir / LENGTHS_FNAME, \"rb\") as f:\n",
    "        lengths = pickle.load(f)\n",
    "    return np.asarray(lengths, dtype=np.int64)\n",
    "\n",
    "def list_split_files(split_dir: Path) -> List[str]:\n",
    "    return sorted(p.name for p in split_dir.iterdir() if p.is_file())\n",
    "\n",
    "def describe_tensor(tensor: torch.Tensor) -> Dict[str, object]:\n",
    "    return {\"shape\": tuple(int(x) for x in tensor.shape),\n",
    "            \"dtype\": str(tensor.dtype),\n",
    "            \"min\": float(tensor.min().item()),\n",
    "            \"max\": float(tensor.max().item())}\n",
    "\n",
    "def gather_episode_meta(dataset_dir: Path) -> Dict[str, Dict[str, object]]:\n",
    "    meta: Dict[str, Dict[str, object]] = {}\n",
    "    for split in SPLITS:\n",
    "        split_dir = dataset_dir / split\n",
    "        lengths = load_lengths(split_dir)\n",
    "        if lengths.size == 0:\n",
    "            min_len = max_len = total_steps = 0\n",
    "        else:\n",
    "            min_len = int(lengths.min())\n",
    "            max_len = int(lengths.max())\n",
    "            total_steps = int(lengths.sum())\n",
    "        meta[split] = {\n",
    "            \"num_episodes\": int(len(lengths)),\n",
    "            \"num_steps\": total_steps,\n",
    "            \"min_len\": min_len,\n",
    "            \"max_len\": max_len,\n",
    "            \"lengths\": lengths,\n",
    "        }\n",
    "    return meta\n",
    "\n",
    "def allocate_subset_counts(total_target: int, split_meta: Dict[str, Dict[str, int]]) -> Dict[str, int]:\n",
    "    total_available = sum(meta[\"num_episodes\"] for meta in split_meta.values())\n",
    "    if total_target >= total_available:\n",
    "        return {split: split_meta[split][\"num_episodes\"] for split in SPLITS}\n",
    "    counts: Dict[str, int] = {}\n",
    "    remaining = total_target\n",
    "    for idx, split in enumerate(SPLITS):\n",
    "        meta = split_meta[split]\n",
    "        if idx == len(SPLITS) - 1:\n",
    "            take = remaining\n",
    "        else:\n",
    "            prop = meta[\"num_episodes\"] / total_available\n",
    "            take = min(meta[\"num_episodes\"], int(round(total_target * prop)))\n",
    "        counts[split] = max(0, min(meta[\"num_episodes\"], take))\n",
    "        remaining -= counts[split]\n",
    "    while remaining > 0:\n",
    "        for split in SPLITS:\n",
    "            if counts[split] < split_meta[split][\"num_episodes\"]:\n",
    "                counts[split] += 1\n",
    "                remaining -= 1\n",
    "                if remaining == 0:\n",
    "                    break\n",
    "    return counts\n",
    "\n",
    "EPISODE_ALIGNED_FILES = [\n",
    "    ABS_ACTIONS_FNAME,\n",
    "    VELOCITIES_FNAME,\n",
    "    ACTIONS_FNAME,\n",
    "    STATES_FNAME,\n",
    "    STATE_CONSTANT_FNAME,\n",
    "    TOKENS_FNAME,\n",
    "] + [f\"rel_actions_discretized_{variant}.pth\" for variant in VARIANTS]\n",
    "\n",
    "def _episode_count_from_obj(obj) -> int | None:\n",
    "    if torch.is_tensor(obj):\n",
    "        return int(obj.shape[0])\n",
    "    if isinstance(obj, (list, tuple)):\n",
    "        return len(obj)\n",
    "    return None\n",
    "\n",
    "def verify_episode_aligned_files(split_dir: Path, expected_count: int):\n",
    "    for fname in EPISODE_ALIGNED_FILES:\n",
    "        path = split_dir / fname\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Missing {path}\")\n",
    "        obj = torch.load(path, map_location=\"cpu\")\n",
    "        count = _episode_count_from_obj(obj)\n",
    "        if count is None:\n",
    "            continue\n",
    "        if count != expected_count:\n",
    "            raise ValueError(f\"{path} has {count} episodes, expected {expected_count}\")\n",
    "\n",
    "def count_observation_files(obs_dir: Path) -> int:\n",
    "    if not obs_dir.exists():\n",
    "        return 0\n",
    "    return sum(1 for _ in obs_dir.glob(\"episode_*\"))\n",
    "\n\ndef flatten_valid_entries(tensor: torch.Tensor, lengths: np.ndarray) -> torch.Tensor:\n    chunks = []\n    for epi in range(tensor.shape[0]):\n        L = int(lengths[epi])\n        if L > 0:\n            chunks.append(tensor[epi, :L])\n    if not chunks:\n        return torch.empty((0, tensor.shape[-1]), dtype=tensor.dtype)\n    return torch.cat(chunks, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === File inventory comparison ===\n",
    "print(\"== File inventory comparison between source and discretized roots ==\")\n",
    "for split in SPLITS:\n",
    "    src_files = set(list_split_files(SRC_DATASET_DIR / split))\n",
    "    dst_files = set(list_split_files(DST_DATASET_DIR / split))\n",
    "    missing = sorted(src_files - dst_files)\n",
    "    extras = sorted(dst_files - src_files)\n",
    "    print(f\"[{split}] missing in discretized: {missing if missing else 'None'}\")\n",
    "    print(f\"[{split}] new files          : {extras if extras else 'None'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Detailed comparison: source vs discretized base dataset ===\n",
    "variant_stats: List[Dict[str, object]] = []\n",
    "source_meta = gather_episode_meta(SRC_DATASET_DIR)\n",
    "discretized_meta = gather_episode_meta(DST_DATASET_DIR)\n",
    "for split in SPLITS:\n",
    "    print(f\"\\n[{split}] episode counts\")\n",
    "    print(f\"source episodes     : {source_meta[split]['num_episodes']}\")\n",
    "    print(f\"discretized episodes: {discretized_meta[split]['num_episodes']}\")\n",
    "    if source_meta[split]['num_episodes'] != discretized_meta[split]['num_episodes']:\n",
    "        raise ValueError(f\"Episode counts disagree for {split}\")\n",
    "    src_lengths = source_meta[split]['lengths']\n",
    "    dst_lengths = discretized_meta[split]['lengths']\n",
    "    if not np.array_equal(src_lengths, dst_lengths):\n",
    "        raise ValueError(f\"Sequence lengths diverged for {split}\")\n",
    "    split_dir_src = SRC_DATASET_DIR / split\n",
    "    split_dir_dst = DST_DATASET_DIR / split\n",
    "    # Compare rel_actions tensors\n",
    "    src_actions = torch.load(split_dir_src / ACTIONS_FNAME, map_location=\"cpu\")\n",
    "    dst_actions = torch.load(split_dir_dst / ACTIONS_FNAME, map_location=\"cpu\")\n",
    "    if src_actions.shape != dst_actions.shape:\n",
    "        raise ValueError(f\"rel_actions shape mismatch for {split}\")\n",
    "    if src_actions.dtype != dst_actions.dtype:\n",
    "        raise ValueError(f\"rel_actions dtype mismatch for {split}\")\n",
    "    actions_equal = bool(torch.equal(src_actions, dst_actions))\n",
    "    max_abs_diff = float((dst_actions - src_actions).abs().max().item())\n",
    "    print(f\"rel_actions identical: {actions_equal} (max diff={max_abs_diff:.3e})\")\n",
    "    # Compare auxiliary continuous files\n",
    "    for fname in (ABS_ACTIONS_FNAME, VELOCITIES_FNAME):\n",
    "        src_tensor = torch.load(split_dir_src / fname, map_location=\"cpu\")\n",
    "        dst_tensor = torch.load(split_dir_dst / fname, map_location=\"cpu\")\n",
    "        if not torch.equal(src_tensor, dst_tensor):\n",
    "            raise ValueError(f\"{fname} mismatches for {split}\")\n",
    "    tokens_src = torch.load(split_dir_src / TOKENS_FNAME, map_location=\"cpu\")\n",
    "    tokens_dst = torch.load(split_dir_dst / TOKENS_FNAME, map_location=\"cpu\")\n",
    "    if len(tokens_src) != len(tokens_dst):\n",
    "        raise ValueError(f\"tokens length mismatch for {split}\")\n",
    "    # Validate discretized variants\n",
    "    for variant in VARIANTS:\n",
    "        var_path = split_dir_dst / f\"rel_actions_discretized_{variant}.pth\"\n",
    "        if not var_path.exists():\n",
    "            raise FileNotFoundError(f\"Missing {var_path}\")\n",
    "        var_tensor = torch.load(var_path, map_location=\"cpu\")\n",
    "        if var_tensor.shape != src_actions.shape:\n",
    "            raise ValueError(f\"Variant {variant} shape mismatch for {split}\")\n",
    "        if var_tensor.dtype != src_actions.dtype:\n",
    "            raise ValueError(f\"Variant {variant} dtype mismatch for {split}\")\n",
    "        delta = var_tensor - src_actions\n",
    "        mean_abs = float(delta.abs().mean().item())\n",
    "        max_abs = float(delta.abs().max().item())\n",
    "        valid_centroids = flatten_valid_entries(var_tensor, dst_lengths)\n",
    "        if valid_centroids.numel() == 0:\n",
    "            unique_centroids = 0\n",
    "        else:\n",
    "            unique_centroids = int(torch.unique(valid_centroids, dim=0).shape[0])\n",
    "        variant_stats.append({\"split\": split, \"variant\": variant, \"mean_abs_diff\": mean_abs, \"max_abs_diff\": max_abs, \"unique_centroids\": unique_centroids})\n",
    "        print(f\"  {variant}: mean|\u0394|={mean_abs:.4f}, max|\u0394|={max_abs:.4f}, unique centroids={unique_centroids}\")\n",
    "        del var_tensor, delta, valid_centroids\n",
    "    states = torch.load(split_dir_dst / STATES_FNAME, map_location=\"cpu\")\n",
    "    states_const = torch.load(split_dir_dst / STATE_CONSTANT_FNAME, map_location=\"cpu\")\n",
    "    if states_const.shape != states.shape:\n",
    "        raise ValueError(f\"states_constant shape mismatch for {split}\")\n",
    "    zero_max = float(states_const.abs().max().item())\n",
    "    print(f\"states_constant zeros check: max|value|={zero_max:.3e}\")\n",
    "    del src_actions, dst_actions, states, states_const, tokens_src, tokens_dst\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Subset dataset verification (1k / 10k trajectories) ===\n",
    "base_counts_for_alloc = {split: {\"num_episodes\": discretized_meta[split][\"num_episodes\"]} for split in SPLITS}\n",
    "for subset_name, target_total in SUBSET_SPECS.items():\n",
    "    subset_root = subset_roots[subset_name]\n",
    "    print(f\"\\n== Checking subset {subset_name} ({target_total} requested trajectories) ==\")\n",
    "    if not subset_root.exists():\n",
    "        print(f\"[skip] {subset_root} does not exist\")\n",
    "        continue\n",
    "    subset_meta = gather_episode_meta(subset_root)\n",
    "    expected_counts = allocate_subset_counts(target_total, base_counts_for_alloc)\n",
    "    total_expected = sum(expected_counts.values())\n",
    "    total_actual = sum(meta[\"num_episodes\"] for meta in subset_meta.values())\n",
    "    print(f\"expected total: {total_expected}, actual total: {total_actual}\")\n",
    "    if total_actual != total_expected:\n",
    "        raise ValueError(f\"Subset {subset_name} has {total_actual} episodes, expected {total_expected}\")\n",
    "    for split in SPLITS:\n",
    "        expected = expected_counts.get(split, 0)\n",
    "        actual = subset_meta[split][\"num_episodes\"]\n",
    "        print(f\"[{subset_name}/{split}] episodes: {actual} (expected {expected}), steps: {subset_meta[split]['num_steps']}\")\n",
    "        if actual != expected:\n",
    "            raise ValueError(f\"Subset {subset_name} split {split} mismatch: {actual} vs {expected}\")\n",
    "        verify_episode_aligned_files(subset_root / split, actual)\n",
    "        lengths = subset_meta[split][\"lengths\"]\n",
    "        if lengths.size:\n",
    "            print(f\"    lengths range: [{lengths.min()}, {lengths.max()}]\")\n",
    "        obs_count = count_observation_files((subset_root / split) / \"obses\")\n",
    "        if obs_count and obs_count != actual:\n",
    "            raise ValueError(f\"Observation file count mismatch for {subset_name}/{split}: {obs_count} vs {actual}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Aggregate discretization stats ===\n",
    "if not variant_stats:\n",
    "    print(\"No variant statistics collected. Run the previous cell first.\")\n",
    "else:\n",
    "    header = f\"{'Split':<8}{'Variant':<20}{'mean|\u0394|':>12}{'max|\u0394|':>12}{'Centroids':>12}\"\n",
    "    print(header)\n",
    "    print('-' * len(header))\n",
    "    for entry in variant_stats:\n",
    "        print(f\"{entry['split']:<8}{entry['variant']:<20}{entry['mean_abs_diff']:>12.6f}{entry['max_abs_diff']:>12.6f}{entry['unique_centroids']:>12}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino_wm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}