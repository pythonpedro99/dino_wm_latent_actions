{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recompute validation metrics from a checkpoint\n",
        "\n",
        "This notebook loads a trained world model checkpoint and runs a validation\n",
        "pass on the validation split to recompute loss metrics. Update the paths\n",
        "in the first code cell before running.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "import hydra\n",
        "import torch\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import custom_resolvers  # registers OmegaConf resolvers\n",
        "from plan import load_model\n",
        "\n",
        "# ---- update these paths ----\n",
        "MODEL_DIR = Path(\"/path/to/your/output/run\").expanduser()\n",
        "CHECKPOINT_NAME = \"model_latest.pth\"  # or e.g. model_10.pth\n",
        "BATCH_SIZE = 64  # set smaller if running on CPU\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load the training config saved alongside the checkpoint\n",
        "model_cfg = OmegaConf.load(MODEL_DIR / \"hydra.yaml\")\n",
        "\n",
        "# Build datasets (same as training)\n",
        "datasets, traj_dsets = hydra.utils.call(\n",
        "    model_cfg.env.dataset,\n",
        "    num_hist=model_cfg.model.num_hist,\n",
        "    num_pred=model_cfg.model.num_pred,\n",
        "    frameskip=model_cfg.dataset.frameskip,\n",
        ")\n",
        "\n",
        "val_dataset = datasets[\"valid\"]\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        ")\n",
        "\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load model from checkpoint\n",
        "model_ckpt = MODEL_DIR / \"checkpoints\" / CHECKPOINT_NAME\n",
        "cfg_dict = {\n",
        "    \"plan_action_type\": str(model_cfg.model.plan_action_type),\n",
        "    \"action_dim\": int(val_dataset.action_dim),\n",
        "    \"is_training\": False,\n",
        "}\n",
        "\n",
        "num_action_repeat = int(model_cfg.model.num_action_repeat)\n",
        "required_keys = {\"model\"}\n",
        "\n",
        "model, _ = load_model(\n",
        "    model_ckpt=model_ckpt,\n",
        "    model_cfg=model_cfg,\n",
        "    cfg_dict=cfg_dict,\n",
        "    num_action_repeat=num_action_repeat,\n",
        "    required_keys=required_keys,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded and set to eval mode.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from einops import rearrange\n",
        "from utils import slice_trajdict_with_t\n",
        "\n",
        "def err_eval_single(model, z_pred, z_tgt):\n",
        "    logs = {}\n",
        "    for k in z_pred.keys():\n",
        "        logs[k] = model.emb_criterion(z_pred[k], z_tgt[k])\n",
        "    return logs\n",
        "\n",
        "def openloop_rollout(model, dset, cfg, num_rollout=10, rand_start_end=True, min_horizon=5):\n",
        "    torch.manual_seed(cfg.training.seed)\n",
        "    min_horizon = min_horizon + cfg.model.num_hist\n",
        "    logs = {}\n",
        "\n",
        "    num_past = [(cfg.model.num_hist, \"\"), (1, \"_1framestart\")]\n",
        "\n",
        "    for idx in range(num_rollout):\n",
        "        valid_traj = False\n",
        "        while not valid_traj:\n",
        "            traj_idx = torch.randint(0, len(dset), ()).item()\n",
        "            obs, act, _, _ = dset[traj_idx]\n",
        "            act = act.to(device)\n",
        "            if rand_start_end:\n",
        "                if obs[\"visual\"].shape[0] > min_horizon * cfg.dataset.frameskip + 1:\n",
        "                    start = torch.randint(0, obs[\"visual\"].shape[0] - min_horizon * cfg.dataset.frameskip - 1, ()).item()\n",
        "                else:\n",
        "                    start = 0\n",
        "                max_horizon = (obs[\"visual\"].shape[0] - start - 1) // cfg.dataset.frameskip\n",
        "                if max_horizon > min_horizon:\n",
        "                    valid_traj = True\n",
        "                    horizon = torch.randint(min_horizon, max_horizon + 1, ()).item()\n",
        "            else:\n",
        "                valid_traj = True\n",
        "                start = 0\n",
        "                horizon = (obs[\"visual\"].shape[0] - 1) // cfg.dataset.frameskip\n",
        "\n",
        "        for k in obs.keys():\n",
        "            obs[k] = obs[k][\n",
        "                start : start + horizon * cfg.dataset.frameskip + 1 : cfg.dataset.frameskip\n",
        "            ]\n",
        "        act = act[start : start + horizon * cfg.dataset.frameskip]\n",
        "        act = rearrange(act, \"(h f) d -> h (f d)\", f=cfg.dataset.frameskip)\n",
        "\n",
        "        obs_g = {k: obs[k][-1].unsqueeze(0).unsqueeze(0).to(device) for k in obs.keys()}\n",
        "        z_g = model.encode_obs(obs_g)\n",
        "        actions = act.unsqueeze(0) if model.use_action_encoder else None\n",
        "\n",
        "        for n_past, postfix in num_past:\n",
        "            obs_full = {k: obs[k].unsqueeze(0).to(device) for k in obs.keys()}\n",
        "            z_obses, _ = model.rollout(obs_full, actions, num_obs_init=n_past)\n",
        "            z_obs_last = slice_trajdict_with_t(z_obses, start_idx=-1, end_idx=None)\n",
        "            div_loss = err_eval_single(model, z_obs_last, z_g)\n",
        "\n",
        "            for k in div_loss.keys():\n",
        "                log_key = f\"z_{k}_err_rollout{postfix}\"\n",
        "                logs.setdefault(log_key, []).append(div_loss[k])\n",
        "\n",
        "    logs = {key: sum(values) / len(values) for key, values in logs.items() if values}\n",
        "    return logs\n",
        "\n",
        "rollout_logs = openloop_rollout(model, traj_dsets[\"valid\"], model_cfg, num_rollout=10, rand_start_end=True)\n",
        "rollout_logs = {f\"val_{k}\": (v.detach().mean().cpu().item() if torch.is_tensor(v) else float(v)) for k, v in rollout_logs.items()}\n",
        "\n",
        "print(\"Open-loop rollout metrics (mean over rollouts):\")\n",
        "for key, value in sorted(rollout_logs.items()):\n",
        "    print(f\"  {key}: {value:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def move_to_device(value, device):\n",
        "    if torch.is_tensor(value):\n",
        "        return value.to(device)\n",
        "    if isinstance(value, dict):\n",
        "        return {k: move_to_device(v, device) for k, v in value.items()}\n",
        "    if isinstance(value, (list, tuple)):\n",
        "        return type(value)(move_to_device(v, device) for v in value)\n",
        "    return value\n",
        "\n",
        "totals = defaultdict(float)\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for obs, act, _ in val_loader:\n",
        "        obs = move_to_device(obs, device)\n",
        "        act = move_to_device(act, device)\n",
        "\n",
        "        _, _, _, loss, loss_components, _ = model(obs, act)\n",
        "\n",
        "        batch_size = act.shape[0]\n",
        "        total_samples += batch_size\n",
        "        totals[\"loss\"] += loss.item() * batch_size\n",
        "\n",
        "        for key, value in loss_components.items():\n",
        "            totals[key] += value.item() * batch_size\n",
        "\n",
        "avg_metrics = {k: v / total_samples for k, v in totals.items()}\n",
        "\n",
        "print(\"Validation metrics (mean over validation set):\")\n",
        "for key, value in sorted(avg_metrics.items()):\n",
        "    print(f\"  {key}: {value:.6f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}