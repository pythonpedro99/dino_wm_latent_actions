{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Recompute validation metrics from a checkpoint\n",
        "\n",
        "This notebook loads a trained world model checkpoint and runs a validation\n",
        "pass on the validation split to recompute loss metrics. Update the paths\n",
        "in the first code cell before running.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "import hydra\n",
        "import torch\n",
        "from omegaconf import OmegaConf\n",
        "\n",
        "import custom_resolvers  # registers OmegaConf resolvers\n",
        "from plan import load_model\n",
        "\n",
        "# ---- update these paths ----\n",
        "MODEL_DIR = Path(\"/path/to/your/output/run\").expanduser()\n",
        "CHECKPOINT_NAME = \"model_latest.pth\"  # or e.g. model_10.pth\n",
        "BATCH_SIZE = 64  # set smaller if running on CPU\n",
        "NUM_WORKERS = 0\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load the training config saved alongside the checkpoint\n",
        "model_cfg = OmegaConf.load(MODEL_DIR / \"hydra.yaml\")\n",
        "\n",
        "# Build datasets (same as training)\n",
        "datasets, traj_dsets = hydra.utils.call(\n",
        "    model_cfg.env.dataset,\n",
        "    num_hist=model_cfg.model.num_hist,\n",
        "    num_pred=model_cfg.model.num_pred,\n",
        "    frameskip=model_cfg.dataset.frameskip,\n",
        ")\n",
        "\n",
        "val_dataset = datasets[\"valid\"]\n",
        "val_loader = torch.utils.data.DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=NUM_WORKERS,\n",
        ")\n",
        "\n",
        "print(f\"Validation samples: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Load model from checkpoint\n",
        "model_ckpt = MODEL_DIR / \"checkpoints\" / CHECKPOINT_NAME\n",
        "cfg_dict = {\n",
        "    \"plan_action_type\": str(model_cfg.model.plan_action_type),\n",
        "    \"action_dim\": int(val_dataset.action_dim),\n",
        "    \"is_training\": False,\n",
        "}\n",
        "\n",
        "num_action_repeat = int(model_cfg.model.num_action_repeat)\n",
        "required_keys = {\"model\"}\n",
        "\n",
        "model, _ = load_model(\n",
        "    model_ckpt=model_ckpt,\n",
        "    model_cfg=model_cfg,\n",
        "    cfg_dict=cfg_dict,\n",
        "    num_action_repeat=num_action_repeat,\n",
        "    required_keys=required_keys,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "print(\"Model loaded and set to eval mode.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "def move_to_device(value, device):\n",
        "    if torch.is_tensor(value):\n",
        "        return value.to(device)\n",
        "    if isinstance(value, dict):\n",
        "        return {k: move_to_device(v, device) for k, v in value.items()}\n",
        "    if isinstance(value, (list, tuple)):\n",
        "        return type(value)(move_to_device(v, device) for v in value)\n",
        "    return value\n",
        "\n",
        "totals = defaultdict(float)\n",
        "total_samples = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for obs, act, _ in val_loader:\n",
        "        obs = move_to_device(obs, device)\n",
        "        act = move_to_device(act, device)\n",
        "\n",
        "        _, _, _, loss, loss_components, _ = model(obs, act)\n",
        "\n",
        "        batch_size = act.shape[0]\n",
        "        total_samples += batch_size\n",
        "        totals[\"loss\"] += loss.item() * batch_size\n",
        "\n",
        "        for key, value in loss_components.items():\n",
        "            totals[key] += value.item() * batch_size\n",
        "\n",
        "avg_metrics = {k: v / total_samples for k, v in totals.items()}\n",
        "\n",
        "print(\"Validation metrics (mean over validation set):\")\n",
        "for key, value in sorted(avg_metrics.items()):\n",
        "    print(f\"  {key}: {value:.6f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}