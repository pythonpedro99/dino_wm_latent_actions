{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f8ee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset dir  : /Users/julianquast/Downloads/pusht_noise\n",
      "Subset specs : {'1k': 1000, '10k': 10000}\n",
      "Random seed  : 0\n",
      "Original train episodes: 18,685\n",
      "\n",
      "== Building subset 1k (1,000 trajectories) ==\n",
      "[1k] new train=900, new val=100 (both from original train)\n",
      "Subset written to /Users/julianquast/Downloads/pusht_noise_1k\n",
      "\n",
      "== Building subset 10k (10,000 trajectories) ==\n",
      "[10k] new train=9,000, new val=1,000 (both from original train)\n",
      "Subset written to /Users/julianquast/Downloads/pusht_noise_10k\n",
      "\n",
      "Done. Subset roots:\n",
      "  1k: /Users/julianquast/Downloads/pusht_noise_1k\n",
      "  10k: /Users/julianquast/Downloads/pusht_noise_10k\n"
     ]
    }
   ],
   "source": [
    "# === SAFE build: uniform-random 1k / 10k subsets (no discretization), train/val both from ORIGINAL train ===\n",
    "# Output:\n",
    "#   <DATASET_DIR>_1k/{train,val}/...\n",
    "#   <DATASET_DIR>_10k/{train,val}/...\n",
    "\n",
    "import gc, json, pickle, shutil, re\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "LENGTHS_FNAME = \"seq_lengths.pkl\"\n",
    "\n",
    "SUBSET_SPECS = {\n",
    "    \"1k\": 1_000,\n",
    "    \"10k\": 10_000,\n",
    "}\n",
    "\n",
    "DATASET_DIR = Path(\"/Users/julianquast/Downloads/pusht_noise\").expanduser()\n",
    "\n",
    "try:\n",
    "    SUBSET_SEED\n",
    "except NameError:\n",
    "    SUBSET_SEED = 0\n",
    "\n",
    "RANDOM_SEED = int(SUBSET_SEED)\n",
    "\n",
    "# set True if you want to rebuild an existing <DATASET_DIR>_10k etc.\n",
    "OVERWRITE = False\n",
    "\n",
    "assert (DATASET_DIR / \"train\").is_dir(), f\"Missing train/: {DATASET_DIR / 'train'}\"\n",
    "assert (DATASET_DIR / \"val\").is_dir(), f\"Missing val/: {DATASET_DIR / 'val'}\"\n",
    "\n",
    "print(f\"Dataset dir  : {DATASET_DIR}\")\n",
    "print(f\"Subset specs : {SUBSET_SPECS}\")\n",
    "print(f\"Random seed  : {RANDOM_SEED}\")\n",
    "\n",
    "# -------------------- Helpers --------------------\n",
    "def load_lengths_only(split_dir: Path) -> np.ndarray:\n",
    "    p = split_dir / LENGTHS_FNAME\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing {LENGTHS_FNAME} in {split_dir}\")\n",
    "    with open(p, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    arr = data.astype(np.int64, copy=False) if isinstance(data, np.ndarray) else np.asarray(data, dtype=np.int64)\n",
    "    if arr.ndim != 1:\n",
    "        arr = arr.reshape(-1)\n",
    "    return arr\n",
    "\n",
    "def _subset_obj(obj: Any, idxs: np.ndarray, orig_count: int) -> Tuple[Any, bool]:\n",
    "    \"\"\"Returns (subset_obj, changed_flag).\"\"\"\n",
    "    if torch.is_tensor(obj):\n",
    "        if obj.ndim >= 1 and obj.shape[0] == orig_count:\n",
    "            out = obj.index_select(0, torch.as_tensor(idxs, dtype=torch.long))\n",
    "            return out, True\n",
    "        return obj, False\n",
    "\n",
    "    if isinstance(obj, np.ndarray):\n",
    "        if obj.ndim >= 1 and obj.shape[0] == orig_count:\n",
    "            return obj[idxs], True\n",
    "        return obj, False\n",
    "\n",
    "    if isinstance(obj, list):\n",
    "        if len(obj) == orig_count:\n",
    "            return [obj[int(i)] for i in idxs], True\n",
    "        return obj, False\n",
    "\n",
    "    if isinstance(obj, tuple):\n",
    "        if len(obj) == orig_count:\n",
    "            return tuple(obj[int(i)] for i in idxs), True\n",
    "        return obj, False\n",
    "\n",
    "    if isinstance(obj, dict):\n",
    "        changed = False\n",
    "        out = {}\n",
    "        for k, v in obj.items():\n",
    "            vv, ch = _subset_obj(v, idxs, orig_count)\n",
    "            out[k] = vv\n",
    "            changed = changed or ch\n",
    "        return out, changed\n",
    "\n",
    "    return obj, False\n",
    "\n",
    "def torch_load_safe(path: Path) -> Any:\n",
    "    \"\"\"\n",
    "    Safe loader:\n",
    "      - tries mmap=True with *string filename* (required by torch internals)\n",
    "      - falls back to normal torch.load on any error\n",
    "    \"\"\"\n",
    "    # IMPORTANT: mmap=True requires a string path in some torch versions\n",
    "    path_str = str(path)\n",
    "    try:\n",
    "        return torch.load(path_str, map_location=\"cpu\", mmap=True)\n",
    "    except Exception:\n",
    "        return torch.load(path_str, map_location=\"cpu\")\n",
    "\n",
    "def subset_tensor_to_path(src_path: Path, dst_path: Path, idxs: np.ndarray, orig_count: int) -> bool:\n",
    "    data = torch_load_safe(src_path)\n",
    "    new_data, changed = _subset_obj(data, idxs, orig_count)\n",
    "    if changed:\n",
    "        dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        torch.save(new_data, str(dst_path))\n",
    "    # free\n",
    "    del data, new_data\n",
    "    gc.collect()\n",
    "    return changed\n",
    "\n",
    "def subset_pickle_to_path(src_path: Path, dst_path: Path, idxs: np.ndarray, orig_count: int) -> bool:\n",
    "    with open(src_path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    new_data, changed = _subset_obj(data, idxs, orig_count)\n",
    "    if changed:\n",
    "        dst_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        with open(dst_path, \"wb\") as f:\n",
    "            pickle.dump(new_data, f)\n",
    "    del data, new_data\n",
    "    gc.collect()\n",
    "    return changed\n",
    "\n",
    "def build_episode_file_map(obs_dir: Path) -> Dict[int, Path]:\n",
    "    mapping: Dict[int, Path] = {}\n",
    "    if not obs_dir.exists():\n",
    "        return mapping\n",
    "    pattern = re.compile(r\"episode_(\\d+)\")\n",
    "    for path in obs_dir.glob(\"episode_*\"):\n",
    "        m = pattern.search(path.stem)\n",
    "        if m:\n",
    "            mapping[int(m.group(1))] = path\n",
    "    return mapping\n",
    "\n",
    "def copy_subset_observation_media(src_obs_dir: Path, dst_obs_dir: Path, idxs: np.ndarray):\n",
    "    \"\"\"Copy only selected episode_* files from src_obs_dir to dst_obs_dir, renaming to contiguous indices.\"\"\"\n",
    "    if not src_obs_dir.exists():\n",
    "        return\n",
    "    idxs = np.asarray(idxs, dtype=np.int64)\n",
    "    mapping = build_episode_file_map(src_obs_dir)\n",
    "\n",
    "    if dst_obs_dir.exists():\n",
    "        shutil.rmtree(dst_obs_dir)\n",
    "    dst_obs_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    pad = max(3, len(str(len(idxs) - 1 if len(idxs) else 0)))\n",
    "    for new_idx, old_idx in enumerate(idxs):\n",
    "        src_path = mapping.get(int(old_idx))\n",
    "        if src_path is None:\n",
    "            raise FileNotFoundError(f\"Missing obs file for episode {old_idx} in {src_obs_dir}\")\n",
    "        dst_path = dst_obs_dir / f\"episode_{new_idx:0{pad}d}{src_path.suffix}\"\n",
    "        shutil.copy2(src_path, dst_path)\n",
    "\n",
    "def copy_non_split_extras(src_root: Path, dst_root: Path):\n",
    "    \"\"\"Copy everything at dataset root except train/ and val/ into dst_root.\"\"\"\n",
    "    dst_root.mkdir(parents=True, exist_ok=True)\n",
    "    for item in src_root.iterdir():\n",
    "        if item.name in (\"train\", \"val\"):\n",
    "            continue\n",
    "        dst_item = dst_root / item.name\n",
    "        if item.is_dir():\n",
    "            shutil.copytree(item, dst_item, dirs_exist_ok=True)\n",
    "        else:\n",
    "            dst_item.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(item, dst_item)\n",
    "\n",
    "def write_train_val_from_train_split(\n",
    "    src_train_dir: Path,\n",
    "    out_train_dir: Path,\n",
    "    out_val_dir: Path,\n",
    "    train_idxs: np.ndarray,\n",
    "    val_idxs: np.ndarray,\n",
    "    orig_count: int,\n",
    "):\n",
    "    \"\"\"\n",
    "    Build out_train_dir and out_val_dir from src_train_dir.\n",
    "\n",
    "    For each item in src_train_dir:\n",
    "      - obses/ is subset-copied for each output\n",
    "      - *.pth/*.pt and *.pkl are subsetted if episode-aligned; otherwise copied as-is\n",
    "      - other files/dirs are copied as-is to both outputs\n",
    "    \"\"\"\n",
    "    out_train_dir.mkdir(parents=True, exist_ok=True)\n",
    "    out_val_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for item in sorted(src_train_dir.iterdir()):\n",
    "        if item.is_dir():\n",
    "            if item.name == \"obses\":\n",
    "                copy_subset_observation_media(item, out_train_dir / \"obses\", train_idxs)\n",
    "                copy_subset_observation_media(item, out_val_dir / \"obses\", val_idxs)\n",
    "            else:\n",
    "                shutil.copytree(item, out_train_dir / item.name, dirs_exist_ok=True)\n",
    "                shutil.copytree(item, out_val_dir / item.name, dirs_exist_ok=True)\n",
    "            gc.collect()\n",
    "            continue\n",
    "\n",
    "        suffix = item.suffix.lower()\n",
    "        dst_train = out_train_dir / item.name\n",
    "        dst_val   = out_val_dir / item.name\n",
    "\n",
    "        if suffix in (\".pth\", \".pt\"):\n",
    "            changed_train = subset_tensor_to_path(item, dst_train, train_idxs, orig_count)\n",
    "            changed_val   = subset_tensor_to_path(item, dst_val,   val_idxs,   orig_count)\n",
    "\n",
    "            if not changed_train:\n",
    "                dst_train.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(item, dst_train)\n",
    "            if not changed_val:\n",
    "                dst_val.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(item, dst_val)\n",
    "\n",
    "        elif suffix == \".pkl\":\n",
    "            changed_train = subset_pickle_to_path(item, dst_train, train_idxs, orig_count)\n",
    "            changed_val   = subset_pickle_to_path(item, dst_val,   val_idxs,   orig_count)\n",
    "\n",
    "            if not changed_train:\n",
    "                dst_train.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(item, dst_train)\n",
    "            if not changed_val:\n",
    "                dst_val.parent.mkdir(parents=True, exist_ok=True)\n",
    "                shutil.copy2(item, dst_val)\n",
    "\n",
    "        else:\n",
    "            dst_train.parent.mkdir(parents=True, exist_ok=True)\n",
    "            dst_val.parent.mkdir(parents=True, exist_ok=True)\n",
    "            shutil.copy2(item, dst_train)\n",
    "            shutil.copy2(item, dst_val)\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "# -------------------- Episode counts --------------------\n",
    "src_train_dir = DATASET_DIR / \"train\"\n",
    "train_avail = int(len(load_lengths_only(src_train_dir)))\n",
    "print(f\"Original train episodes: {train_avail:,}\")\n",
    "assert train_avail > 0, \"No train episodes available.\"\n",
    "\n",
    "# -------------------- Build subsets --------------------\n",
    "subset_roots: Dict[str, Path] = {}\n",
    "\n",
    "for subset_name, target_total in SUBSET_SPECS.items():\n",
    "    if target_total > train_avail:\n",
    "        raise ValueError(f\"Requested {target_total} episodes but only {train_avail} train episodes available.\")\n",
    "\n",
    "    subset_root = DATASET_DIR.parent / f\"{DATASET_DIR.name}_{subset_name}\"\n",
    "    subset_roots[subset_name] = subset_root\n",
    "\n",
    "    if subset_root.exists():\n",
    "        if OVERWRITE:\n",
    "            print(f\"[overwrite] removing existing {subset_root}\")\n",
    "            shutil.rmtree(subset_root)\n",
    "        else:\n",
    "            print(f\"[skip] {subset_root} already exists\")\n",
    "            continue\n",
    "\n",
    "    print(f\"\\n== Building subset {subset_name} ({target_total:,} trajectories) ==\")\n",
    "\n",
    "    # Copy extras (anything not train/val)\n",
    "    subset_root.mkdir(parents=True, exist_ok=True)\n",
    "    copy_non_split_extras(DATASET_DIR, subset_root)\n",
    "\n",
    "    # Uniform sample from ORIGINAL train, then disjoint 90/10 split\n",
    "    rng = np.random.default_rng(RANDOM_SEED + target_total)\n",
    "    sampled = rng.choice(train_avail, size=target_total, replace=False)\n",
    "    perm = rng.permutation(len(sampled))\n",
    "\n",
    "    train_target = int(round(target_total * 0.9))\n",
    "    val_target   = target_total - train_target\n",
    "\n",
    "    train_idxs = np.sort(sampled[perm[:train_target]])\n",
    "    val_idxs   = np.sort(sampled[perm[train_target:]])\n",
    "\n",
    "    assert len(train_idxs) == train_target and len(val_idxs) == val_target\n",
    "    assert len(np.intersect1d(train_idxs, val_idxs)) == 0\n",
    "\n",
    "    print(f\"[{subset_name}] new train={len(train_idxs):,}, new val={len(val_idxs):,} (both from original train)\")\n",
    "\n",
    "    out_train_dir = subset_root / \"train\"\n",
    "    out_val_dir   = subset_root / \"val\"\n",
    "\n",
    "    write_train_val_from_train_split(\n",
    "        src_train_dir=src_train_dir,\n",
    "        out_train_dir=out_train_dir,\n",
    "        out_val_dir=out_val_dir,\n",
    "        train_idxs=train_idxs,\n",
    "        val_idxs=val_idxs,\n",
    "        orig_count=train_avail,\n",
    "    )\n",
    "\n",
    "    info = {\n",
    "        \"source_dataset\": str(DATASET_DIR),\n",
    "        \"subset_name\": subset_name,\n",
    "        \"target_total\": int(target_total),\n",
    "        \"train_episodes\": int(len(train_idxs)),\n",
    "        \"val_episodes\": int(len(val_idxs)),\n",
    "        \"orig_train_episodes\": int(train_avail),\n",
    "        \"seed\": int(RANDOM_SEED),\n",
    "        \"sampling\": \"uniform sample target_total from original train (no replacement); permute and split 90/10 (disjoint).\",\n",
    "        \"overwrite\": bool(OVERWRITE),\n",
    "    }\n",
    "    with open(subset_root / \"subset_info.json\", \"w\") as f:\n",
    "        json.dump(info, f, indent=2)\n",
    "\n",
    "    gc.collect()\n",
    "    print(f\"Subset written to {subset_root}\")\n",
    "\n",
    "print(\"\\nDone. Subset roots:\")\n",
    "for k, v in subset_roots.items():\n",
    "    print(f\"  {k}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f123f21c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Checking subset: /Users/julianquast/Downloads/pusht_noise_1k ===\n",
      "  split: train\n",
      "    episodes (seq_lengths): 900 | minT=49 maxT=246 meanT=125.83\n",
      "    obses/: 900 episode_* files\n",
      "    - rel_actions.pth: OK shape=(900, 246, 2)\n",
      "    - states.pth: OK shape=(900, 246, 5)\n",
      "    - states_constant.pth: (missing) [SKIP]\n",
      "    other tensor files (top-level): 3\n",
      "    - abs_actions.pth: OK shape=(900, 246, 2)\n",
      "    - tokens.pth: type=list [INFO]\n",
      "    - velocities.pth: OK shape=(900, 246, 2)\n",
      "    RESULT: OK\n",
      "\n",
      "  split: val\n",
      "    episodes (seq_lengths): 100 | minT=49 maxT=229 meanT=126.56\n",
      "    obses/: 100 episode_* files\n",
      "    - rel_actions.pth: OK shape=(100, 246, 2)\n",
      "    - states.pth: OK shape=(100, 246, 5)\n",
      "    - states_constant.pth: (missing) [SKIP]\n",
      "    other tensor files (top-level): 3\n",
      "    - abs_actions.pth: OK shape=(100, 246, 2)\n",
      "    - tokens.pth: type=list [INFO]\n",
      "    - velocities.pth: OK shape=(100, 246, 2)\n",
      "    RESULT: OK\n",
      "\n",
      "\n",
      "=== Checking subset: /Users/julianquast/Downloads/pusht_noise_10k ===\n",
      "  split: train\n",
      "    episodes (seq_lengths): 9,000 | minT=49 maxT=246 meanT=124.68\n",
      "    obses/: 9,000 episode_* files\n",
      "    - rel_actions.pth: OK shape=(9000, 246, 2)\n",
      "    - states.pth: OK shape=(9000, 246, 5)\n",
      "    - states_constant.pth: (missing) [SKIP]\n",
      "    other tensor files (top-level): 3\n",
      "    - abs_actions.pth: OK shape=(9000, 246, 2)\n",
      "    - tokens.pth: type=list [INFO]\n",
      "    - velocities.pth: OK shape=(9000, 246, 2)\n",
      "    RESULT: OK\n",
      "\n",
      "  split: val\n",
      "    episodes (seq_lengths): 1,000 | minT=49 maxT=246 meanT=123.03\n",
      "    obses/: 1,000 episode_* files\n",
      "    - rel_actions.pth: OK shape=(1000, 246, 2)\n",
      "    - states.pth: OK shape=(1000, 246, 5)\n",
      "    - states_constant.pth: (missing) [SKIP]\n",
      "    other tensor files (top-level): 3\n",
      "    - abs_actions.pth: OK shape=(1000, 246, 2)\n",
      "    - tokens.pth: type=list [INFO]\n",
      "    - velocities.pth: OK shape=(1000, 246, 2)\n",
      "    RESULT: OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === Sanity-check subsets: seq_lengths, obses, and episode-aligned action/state tensors ===\n",
    "# Checks:\n",
    "#  - seq_lengths.pkl exists, sane, and defines N episodes\n",
    "#  - obses/episode_* count == N (if obses exists) and indices are contiguous\n",
    "#  - rel_actions.pth (if present) has first dim == N\n",
    "#  - states.pth / states_constant.pth (if present) has first dim == N\n",
    "#  - any other *.pth/*.pt tensors at top-level with first dim == N are reported\n",
    "\n",
    "import pickle, re, gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "LENGTHS_FNAME = \"seq_lengths.pkl\"\n",
    "ACTIONS_FNAME = \"rel_actions.pth\"\n",
    "STATES_FNAME = \"states.pth\"\n",
    "STATES_CONST_FNAME = \"states_constant.pth\"\n",
    "\n",
    "DATASET_DIR = Path(\"/Users/julianquast/Downloads/pusht_noise\").expanduser()\n",
    "SUBSET_DIRS = [\n",
    "    DATASET_DIR.parent / f\"{DATASET_DIR.name}_1k\",\n",
    "    DATASET_DIR.parent / f\"{DATASET_DIR.name}_10k\",\n",
    "]\n",
    "\n",
    "def load_lengths(split_dir: Path) -> np.ndarray:\n",
    "    p = split_dir / LENGTHS_FNAME\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing {p}\")\n",
    "    with open(p, \"rb\") as f:\n",
    "        x = pickle.load(f)\n",
    "    x = x.astype(np.int64, copy=False) if isinstance(x, np.ndarray) else np.asarray(x, dtype=np.int64)\n",
    "    return x.reshape(-1)\n",
    "\n",
    "def count_obs_eps(obs_dir: Path) -> int:\n",
    "    if not obs_dir.exists():\n",
    "        return 0\n",
    "    pat = re.compile(r\"episode_(\\d+)\")\n",
    "    ids = []\n",
    "    for p in obs_dir.glob(\"episode_*\"):\n",
    "        m = pat.search(p.stem)\n",
    "        if m:\n",
    "            ids.append(int(m.group(1)))\n",
    "    if not ids:\n",
    "        return 0\n",
    "    ids_sorted = sorted(ids)\n",
    "    if ids_sorted[0] != 0 or ids_sorted[-1] != len(ids_sorted) - 1:\n",
    "        raise ValueError(\n",
    "            f\"obses episode indices not contiguous in {obs_dir} \"\n",
    "            f\"(min={ids_sorted[0]}, max={ids_sorted[-1]}, n={len(ids_sorted)})\"\n",
    "        )\n",
    "    return len(ids_sorted)\n",
    "\n",
    "def torch_load_safe(path: Path):\n",
    "    # Avoid mmap quirks; keep it simple for checks.\n",
    "    return torch.load(str(path), map_location=\"cpu\")\n",
    "\n",
    "def check_tensor_first_dim(path: Path, expected_n: int) -> bool:\n",
    "    \"\"\"Returns True if OK, False if mismatch. Prints details.\"\"\"\n",
    "    if not path.exists():\n",
    "        print(f\"    - {path.name}: (missing) [SKIP]\")\n",
    "        return True\n",
    "    try:\n",
    "        obj = torch_load_safe(path)\n",
    "    except Exception as e:\n",
    "        print(f\"    - {path.name}: could not load ({type(e).__name__}: {e})\")\n",
    "        return False\n",
    "\n",
    "    ok = True\n",
    "    if torch.is_tensor(obj):\n",
    "        if obj.ndim < 1:\n",
    "            print(f\"    - {path.name}: tensor has ndim<1 [WARN]\")\n",
    "        elif obj.shape[0] != expected_n:\n",
    "            print(f\"    - {path.name}: BAD first dim={obj.shape[0]} expected={expected_n}\")\n",
    "            ok = False\n",
    "        else:\n",
    "            print(f\"    - {path.name}: OK shape={tuple(obj.shape)}\")\n",
    "    elif isinstance(obj, dict):\n",
    "        # Some files are dicts; check any tensors inside that look episode-aligned.\n",
    "        found_any = False\n",
    "        for k, v in obj.items():\n",
    "            if torch.is_tensor(v) and v.ndim >= 1:\n",
    "                found_any = True\n",
    "                if v.shape[0] != expected_n:\n",
    "                    print(f\"    - {path.name}[{k!r}]: BAD first dim={v.shape[0]} expected={expected_n}\")\n",
    "                    ok = False\n",
    "                else:\n",
    "                    print(f\"    - {path.name}[{k!r}]: OK shape={tuple(v.shape)}\")\n",
    "        if not found_any:\n",
    "            print(f\"    - {path.name}: dict (no tensor fields checked) [INFO]\")\n",
    "    else:\n",
    "        print(f\"    - {path.name}: type={type(obj).__name__} (not checked) [INFO]\")\n",
    "\n",
    "    del obj\n",
    "    gc.collect()\n",
    "    return ok\n",
    "\n",
    "def check_split(split_dir: Path):\n",
    "    lengths = load_lengths(split_dir)\n",
    "    n = len(lengths)\n",
    "\n",
    "    print(f\"  split: {split_dir.name}\")\n",
    "    print(f\"    episodes (seq_lengths): {n:,} | minT={int(lengths.min())} maxT={int(lengths.max())} meanT={float(lengths.mean()):.2f}\")\n",
    "\n",
    "    if np.any(lengths <= 0):\n",
    "        raise ValueError(f\"{split_dir}: seq_lengths contains non-positive values\")\n",
    "    if np.any(~np.isfinite(lengths)):\n",
    "        raise ValueError(f\"{split_dir}: seq_lengths contains non-finite values\")\n",
    "\n",
    "    obs_dir = split_dir / \"obses\"\n",
    "    if obs_dir.exists():\n",
    "        obs_n = count_obs_eps(obs_dir)\n",
    "        print(f\"    obses/: {obs_n:,} episode_* files\")\n",
    "        if obs_n != n:\n",
    "            print(f\"    WARNING: obses count ({obs_n}) != seq_lengths count ({n})\")\n",
    "    else:\n",
    "        print(f\"    obses/: (not present)\")\n",
    "\n",
    "    # Explicit action/state checks\n",
    "    ok = True\n",
    "    ok &= check_tensor_first_dim(split_dir / ACTIONS_FNAME, n)\n",
    "    ok &= check_tensor_first_dim(split_dir / STATES_FNAME, n)\n",
    "    ok &= check_tensor_first_dim(split_dir / STATES_CONST_FNAME, n)\n",
    "\n",
    "    # Optional: scan other top-level tensor files and report episode-aligned ones\n",
    "    extra = sorted(list(split_dir.glob(\"*.pth\")) + list(split_dir.glob(\"*.pt\")))\n",
    "    extra = [p for p in extra if p.name not in (ACTIONS_FNAME, STATES_FNAME, STATES_CONST_FNAME)]\n",
    "    if extra:\n",
    "        print(f\"    other tensor files (top-level): {len(extra)}\")\n",
    "        for p in extra:\n",
    "            # only print if it matches N; otherwise just note mismatch\n",
    "            try:\n",
    "                obj = torch_load_safe(p)\n",
    "                if torch.is_tensor(obj) and obj.ndim >= 1:\n",
    "                    tag = \"OK\" if obj.shape[0] == n else \"mismatch\"\n",
    "                    print(f\"    - {p.name}: {tag} shape={tuple(obj.shape)}\")\n",
    "                else:\n",
    "                    print(f\"    - {p.name}: type={type(obj).__name__} [INFO]\")\n",
    "                del obj\n",
    "            except Exception as e:\n",
    "                print(f\"    - {p.name}: could not load ({type(e).__name__}: {e})\")\n",
    "            gc.collect()\n",
    "\n",
    "    print(\"    RESULT:\", \"OK\\n\" if ok else \"HAS ISSUES (see above)\\n\")\n",
    "\n",
    "for root in SUBSET_DIRS:\n",
    "    print(f\"\\n=== Checking subset: {root} ===\")\n",
    "    if not root.exists():\n",
    "        print(\"  MISSING (dir does not exist)\")\n",
    "        continue\n",
    "    for split in (\"train\", \"val\"):\n",
    "        split_dir = root / split\n",
    "        if not split_dir.exists():\n",
    "            print(f\"  MISSING split dir: {split_dir}\")\n",
    "            continue\n",
    "        check_split(split_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ac19dc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Stats for subset 1k: /Users/julianquast/Downloads/pusht_noise_1k ===\n",
      "  split: train\n",
      "    - rel_actions.pth [RAW]: samples=221,400 feat_dim=2 (scale=1.0, stride=1)\n",
      "      mean: [-0.312646,  0.260833]\n",
      "      std : [15.063884, 14.829579]\n",
      "    - rel_actions.pth [SCALED/STRIDED]: samples=221,400 feat_dim=2 (scale=100.0, stride=1)\n",
      "      mean: [-0.003126,  0.002608]\n",
      "      std : [0.150639, 0.148296]\n",
      "    - states.pth: samples=221,400 feat_dim=5 (scale=1.0, stride=1)\n",
      "      mean: [118.281876, 148.32808 , 125.58703 , 139.52927 ,   1.085302]\n",
      "      std : [137.72513, 161.16718, 133.32805, 145.71861,   1.73888]\n",
      "    - states_constant.pth: missing\n",
      "  split: val\n",
      "    - rel_actions.pth [RAW]: samples=24,600 feat_dim=2 (scale=1.0, stride=1)\n",
      "      mean: [-0.369958,  0.402305]\n",
      "      std : [15.223104, 15.381005]\n",
      "    - rel_actions.pth [SCALED/STRIDED]: samples=24,600 feat_dim=2 (scale=100.0, stride=1)\n",
      "      mean: [-0.0037  ,  0.004023]\n",
      "      std : [0.152231, 0.15381 ]\n",
      "    - states.pth: samples=24,600 feat_dim=5 (scale=1.0, stride=1)\n",
      "      mean: [117.4255  , 151.69733 , 125.03642 , 143.43373 ,   1.047184]\n",
      "      std : [136.12288 , 163.31985 , 133.93793 , 148.48428 ,   1.644893]\n",
      "    - states_constant.pth: missing\n",
      "\n",
      "=== Stats for subset 10k: /Users/julianquast/Downloads/pusht_noise_10k ===\n",
      "  split: train\n",
      "    - rel_actions.pth [RAW]: samples=2,214,000 feat_dim=2 (scale=1.0, stride=1)\n",
      "      mean: [-0.36953 ,  0.328818]\n",
      "      std : [14.843125, 14.722512]\n",
      "    - rel_actions.pth [SCALED/STRIDED]: samples=2,214,000 feat_dim=2 (scale=100.0, stride=1)\n",
      "      mean: [-0.003695,  0.003288]\n",
      "      std : [0.148431, 0.147225]\n",
      "    - states.pth: samples=2,214,000 feat_dim=5 (scale=1.0, stride=1)\n",
      "      mean: [115.863365, 148.13002 , 123.305336, 139.50023 ,   1.080451]\n",
      "      std : [135.9158  , 162.18025 , 132.06897 , 147.15077 ,   1.735476]\n",
      "    - states_constant.pth: missing\n",
      "  split: val\n",
      "    - rel_actions.pth [RAW]: samples=246,000 feat_dim=2 (scale=1.0, stride=1)\n",
      "      mean: [-0.430338,  0.371427]\n",
      "      std : [14.66584 , 14.600504]\n",
      "    - rel_actions.pth [SCALED/STRIDED]: samples=246,000 feat_dim=2 (scale=100.0, stride=1)\n",
      "      mean: [-0.004303,  0.003714]\n",
      "      std : [0.146658, 0.146005]\n",
      "    - states.pth: samples=246,000 feat_dim=5 (scale=1.0, stride=1)\n",
      "      mean: [115.16242 , 146.1749  , 121.974785, 137.10294 ,   1.082811]\n",
      "      std : [136.57123 , 162.11267 , 131.85356 , 146.97966 ,   1.756644]\n",
      "    - states_constant.pth: missing\n"
     ]
    }
   ],
   "source": [
    "# === Compute mean/std for actions + states (streaming; safe for large files) ===\n",
    "# Computes per-dimension mean/std over ALL timesteps of all episodes in a split.\n",
    "# Supports:\n",
    "#   actions: [N, T, A] or [N, A]\n",
    "#   states : [N, T, D] or [N, D]\n",
    "#\n",
    "# Updates vs your version:\n",
    "#   - Optional ACTION_SCALE (e.g. 100.0) applied BEFORE stats\n",
    "#   - Optional TIME_STRIDE (e.g. 5) applied on time axis BEFORE stats\n",
    "#   - Reports BOTH raw and scaled/strided stats for actions (so you can compare)\n",
    "#   - Still streams to avoid RAM spikes\n",
    "\n",
    "import gc\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "from typing import Any\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "torch.set_num_threads(1)\n",
    "\n",
    "ACTIONS_FNAME = \"rel_actions.pth\"\n",
    "STATES_FNAME = \"states.pth\"\n",
    "STATES_CONST_FNAME = \"states_constant.pth\"\n",
    "\n",
    "DATASET_DIR = Path(\"/Users/julianquast/Downloads/pusht_noise\").expanduser()\n",
    "TARGETS = [\n",
    "    (DATASET_DIR.parent / f\"{DATASET_DIR.name}_1k\", \"1k\"),\n",
    "    (DATASET_DIR.parent / f\"{DATASET_DIR.name}_10k\", \"10k\"),\n",
    "]\n",
    "\n",
    "# If memory is tight, reduce this. If it's fast, you can increase.\n",
    "BATCH_EPISODES = 256\n",
    "\n",
    "# --- YOUR NORMALIZATION / SAMPLING SETTINGS ---\n",
    "ACTION_SCALE = 100.0     # set to 1.0 to disable; if you normalize actions by /100 in training, keep 100.0\n",
    "TIME_STRIDE = 1          # set to 5 if you want stats computed on x[:, ::5, :] (training-time stride)\n",
    "\n",
    "# -------------------- Core streaming stats --------------------\n",
    "def _flatten_samples(x: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Flatten everything except last dim to [num_samples, feat_dim].\n",
    "    \"\"\"\n",
    "    if x.ndim == 1:\n",
    "        return x.reshape(-1, 1)\n",
    "    return x.reshape(-1, x.shape[-1])\n",
    "\n",
    "def _stream_mean_std_rows(x2: torch.Tensor, chunk_rows: int = 1_000_000) -> tuple[torch.Tensor, torch.Tensor, int]:\n",
    "    \"\"\"\n",
    "    x2: [num_samples, feat_dim] float/double tensor on CPU\n",
    "    returns mean, std (float32), and sample count.\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    mean = torch.zeros(x2.shape[1], dtype=torch.float64)\n",
    "    M2 = torch.zeros(x2.shape[1], dtype=torch.float64)\n",
    "\n",
    "    for start in range(0, x2.shape[0], chunk_rows):\n",
    "        xb = x2[start:start + chunk_rows].to(torch.float64)\n",
    "        nb = xb.shape[0]\n",
    "        if nb == 0:\n",
    "            continue\n",
    "\n",
    "        b_mean = xb.mean(dim=0)\n",
    "        b_var = xb.var(dim=0, unbiased=False)\n",
    "\n",
    "        if n == 0:\n",
    "            mean = b_mean\n",
    "            M2 = b_var * nb\n",
    "            n = nb\n",
    "        else:\n",
    "            delta = b_mean - mean\n",
    "            new_n = n + nb\n",
    "            mean = mean + delta * (nb / new_n)\n",
    "            M2 = M2 + b_var * nb + (delta * delta) * (n * nb / new_n)\n",
    "            n = new_n\n",
    "\n",
    "    var = M2 / max(n, 1)\n",
    "    std = torch.sqrt(var)\n",
    "    return mean.to(torch.float32), std.to(torch.float32), int(n)\n",
    "\n",
    "def _load_tensor(path: Path) -> Any:\n",
    "    return torch.load(str(path), map_location=\"cpu\")\n",
    "\n",
    "def _extract_tensor(obj: Any, fname: str) -> torch.Tensor | None:\n",
    "    if torch.is_tensor(obj):\n",
    "        return obj\n",
    "    if isinstance(obj, dict):\n",
    "        # pick first tensor value (heuristic)\n",
    "        for v in obj.values():\n",
    "            if torch.is_tensor(v):\n",
    "                return v\n",
    "    return None\n",
    "\n",
    "def _apply_time_stride(x: torch.Tensor, stride: int) -> torch.Tensor:\n",
    "    if stride <= 1:\n",
    "        return x\n",
    "    # Only applies cleanly if there is a time dimension.\n",
    "    # Convention here: [N, T, D] -> stride on axis 1.\n",
    "    if x.ndim >= 3:\n",
    "        return x[:, ::stride, ...]\n",
    "    return x\n",
    "\n",
    "def compute_stats_for_file(\n",
    "    split_dir: Path,\n",
    "    fname: str,\n",
    "    *,\n",
    "    action_scale: float = 1.0,\n",
    "    time_stride: int = 1,\n",
    ") -> dict:\n",
    "    p = split_dir / fname\n",
    "    if not p.exists():\n",
    "        return {\"file\": fname, \"present\": False}\n",
    "\n",
    "    obj = _load_tensor(p)\n",
    "    x = _extract_tensor(obj, fname)\n",
    "    if x is None:\n",
    "        return {\"file\": fname, \"present\": True, \"error\": f\"Not a tensor or dict-with-tensor: {type(obj).__name__}\"}\n",
    "\n",
    "    if x.ndim < 1:\n",
    "        return {\"file\": fname, \"present\": True, \"error\": f\"Tensor has ndim={x.ndim}\"}\n",
    "\n",
    "    # Apply time stride if applicable\n",
    "    x = _apply_time_stride(x, time_stride)\n",
    "\n",
    "    # Apply scaling (mainly for actions)\n",
    "    if action_scale != 1.0:\n",
    "        x = x / float(action_scale)\n",
    "\n",
    "    N = int(x.shape[0])\n",
    "\n",
    "    # Stream over episodes to control memory\n",
    "    total_n = 0\n",
    "    mean = torch.zeros(x.shape[-1] if x.ndim > 1 else 1, dtype=torch.float64)\n",
    "    M2 = torch.zeros_like(mean)\n",
    "\n",
    "    for s in range(0, N, BATCH_EPISODES):\n",
    "        xb = x[s:s + BATCH_EPISODES]\n",
    "        x2 = _flatten_samples(xb)  # [num_samples, feat_dim]\n",
    "\n",
    "        b_mean, b_std, nb = _stream_mean_std_rows(x2)\n",
    "        b_mean64 = b_mean.to(torch.float64)\n",
    "        b_var64 = (b_std.to(torch.float64) ** 2)\n",
    "\n",
    "        if total_n == 0:\n",
    "            mean = b_mean64\n",
    "            M2 = b_var64 * nb\n",
    "            total_n = nb\n",
    "        else:\n",
    "            delta = b_mean64 - mean\n",
    "            new_n = total_n + nb\n",
    "            mean = mean + delta * (nb / new_n)\n",
    "            M2 = M2 + b_var64 * nb + (delta * delta) * (total_n * nb / new_n)\n",
    "            total_n = new_n\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "    var = M2 / max(total_n, 1)\n",
    "    std = torch.sqrt(var)\n",
    "\n",
    "    # cleanup\n",
    "    del obj, x\n",
    "    gc.collect()\n",
    "\n",
    "    return {\n",
    "        \"file\": fname,\n",
    "        \"present\": True,\n",
    "        \"samples\": int(total_n),\n",
    "        \"feat_dim\": int(mean.numel()),\n",
    "        \"mean\": mean.to(torch.float32).numpy(),\n",
    "        \"std\": std.to(torch.float32).numpy(),\n",
    "        \"action_scale\": float(action_scale),\n",
    "        \"time_stride\": int(time_stride),\n",
    "    }\n",
    "\n",
    "def pretty_print_stats(stats: dict, max_dims: int = 10, label: str = \"\"):\n",
    "    if not stats.get(\"present\", False):\n",
    "        print(f\"    - {stats['file']}{label}: missing\")\n",
    "        return\n",
    "    if \"error\" in stats:\n",
    "        print(f\"    - {stats['file']}{label}: ERROR: {stats['error']}\")\n",
    "        return\n",
    "\n",
    "    mean = stats[\"mean\"]\n",
    "    std = stats[\"std\"]\n",
    "    d = stats[\"feat_dim\"]\n",
    "    shown = min(d, max_dims)\n",
    "\n",
    "    def fmt(arr):\n",
    "        return np.array2string(arr[:shown], precision=6, separator=\", \")\n",
    "\n",
    "    tail = \"\" if d <= max_dims else f\" ... (+{d-max_dims} dims)\"\n",
    "    print(f\"    - {stats['file']}{label}: samples={stats['samples']:,} feat_dim={d} (scale={stats['action_scale']}, stride={stats['time_stride']})\")\n",
    "    print(f\"      mean: {fmt(mean)}{tail}\")\n",
    "    print(f\"      std : {fmt(std)}{tail}\")\n",
    "\n",
    "for root, tag in TARGETS:\n",
    "    print(f\"\\n=== Stats for subset {tag}: {root} ===\")\n",
    "    if not root.exists():\n",
    "        print(\"  MISSING subset directory\")\n",
    "        continue\n",
    "\n",
    "    for split in (\"train\", \"val\"):\n",
    "        split_dir = root / split\n",
    "        if not split_dir.exists():\n",
    "            print(f\"  MISSING split: {split_dir}\")\n",
    "            continue\n",
    "\n",
    "        print(f\"  split: {split}\")\n",
    "\n",
    "        # Actions: report RAW and (optionally) NORMALIZED/STRIDED\n",
    "        a_raw = compute_stats_for_file(split_dir, ACTIONS_FNAME, action_scale=1.0, time_stride=1)\n",
    "        pretty_print_stats(a_raw, label=\" [RAW]\")\n",
    "\n",
    "        a_norm = compute_stats_for_file(split_dir, ACTIONS_FNAME, action_scale=ACTION_SCALE, time_stride=TIME_STRIDE)\n",
    "        # Only print normalized if it differs from raw settings\n",
    "        if ACTION_SCALE != 1.0 or TIME_STRIDE != 1:\n",
    "            pretty_print_stats(a_norm, label=f\" [SCALED/STRIDED]\")\n",
    "\n",
    "        # States: typically not scaled; optionally strided if you want stats at training stride\n",
    "        s_stats = compute_stats_for_file(split_dir, STATES_FNAME, action_scale=1.0, time_stride=TIME_STRIDE)\n",
    "        sc_stats = compute_stats_for_file(split_dir, STATES_CONST_FNAME, action_scale=1.0, time_stride=TIME_STRIDE)\n",
    "\n",
    "        pretty_print_stats(s_stats)\n",
    "        pretty_print_stats(sc_stats)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dino_wm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
