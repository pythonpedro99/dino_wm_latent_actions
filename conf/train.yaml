defaults:
  - _self_
  - env: pusht
  - encoder: dino 
  - action_encoder: proprio
  - decoder: vqvae
  - predictor: vit
  - latent_action_model: default
  - vq_model: default
  - override hydra/launcher: submitit_slurm

# base path to save model outputs. Checkpoints will be saved to ${ckpt_base_path}/outputs.
ckpt_base_path: /content/LatentActionModel # put absolute path here
debug: False 

hydra:
  run:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${ckpt_base_path}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
  launcher:
    submitit_folder: ${hydra.sweep.dir}/.submitit/%j
    nodes: 1
    tasks_per_node: 1
    cpus_per_task: 8
    mem_gb: 512
    gres: "gpu:h100:1"
    timeout_min: 2880
    setup: ["export DEBUGVAR=$(scontrol show hostnames $SLURM_JOB_NODELIST)",
            export MASTER_ADDR="$(scontrol show hostnames $SLURM_JOB_NODELIST | head -n 1)",
            "export MASTER_PORT=$(for port in $(shuf -i 30000-65500 -n 20); do if [[ $(netstat -tupln 2>&1 | grep $port | wc -l) -eq 0 ]] ; then echo $port; break; fi; done;)",]


training:
  seed: 0
  epochs: 10
  batch_size: 64                   # should >= nodes * tasks_per_node
  save_every_x_epoch: 0
  save_every_x_steps: 2000
  num_reconstruct_samples: 0
  num_workers: 4
  encoder_lr: 0
  decoder_lr: 0
  predictor_lr: 5e-5
  action_encoder_lr: 2e-4 
  latent_lr: 2.5e-5


dataset:
  normalize_action: True
  action_scale: 100.0
  frameskip: 5
  img_size: 224 

model:
  _target_: models.visual_world_model.VWorldModel
  use_action_encoder: false
  use_lam: true
  use_vq: true
  has_predictor: True 
  has_decoder: False 
  plan_action_type: raw  # always use raw for training
  compute_prior_stats: false
  is_training: true      # always true

  train_encoder: false
  train_predictor: true
  train_decoder: false
  train_action_encoder: false   # explicit, even though use_action_encoder=false
  train_lam: true               # must be true only if use_lam=true

  action_emb_dim: 32 
  num_action_repeat: 1
  num_hist: 1
  num_pred: 1 # only supports 1
  concat_dim: 1  # only supports 1 
  
  codebook_splits: 1
  codebook_dim: 32              # latent_action_dim must be = codebook_splits * codebook_dim 
  latent_action_dim: 32
  num_codes: 16
  commitment: 0.1
  ema_decay: 0.95

two_phase:
  enabled: true
  warmup_steps: 2000
  mix_steps: 1000

metrics:
  swap_check_every_n_steps: 100
  ppl_check_every_n_steps: 200
  deadcode_check_every_n_steps: 1000
  ppl_batch_window: 200
  deadcode_batch_window: 1000
  swap_bad_streak_to_flag: 5
  shuffle_u_threshold: 0.05
  shuffle_z_threshold: 0.65
  ppl_norm_threshold: 0.1
  deadcode_threshold: 0.5


# Planning params for planning eval jobs launched during training
plan_settings:
  # plan_cfg_path: conf/plan.yaml # set to null for no planning evals
  plan_cfg_path: null
  planner: ['gd', 'cem']
  goal_source: ['dset', 'random_state']
  goal_H: [5]
  alpha: [0.1, 1]
